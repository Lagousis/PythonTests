{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a NN without a framework\n",
    "Ideas taken from https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a NN with input x and output y. It has a hidden layer with 4 nodes. Weights from input layer to hidder layer as denoted as W1 (biases=b1) and from hidden layer to the output layer as W2 (biases=b2)\n",
    "Activate function will sigmoid, let's represent it with s\n",
    "\n",
    "y' = s( W2 * ( s(W1 * x + b1) ) + b2 )\n",
    "\n",
    "You might notice that in the equation above, the weights W and the biases b are the only variables that affects the output Å·."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use squared error as loss function. Our goal in training is to find the best set of weights and biases that minimizes the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, hidden_nodes):\n",
    "        self.input = x\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.weights1 = np.random.rand(self.input.shape[1], self.hidden_nodes) \n",
    "        self.weights2 = np.random.rand(self.hidden_nodes, 1)                 \n",
    "        self.y = y\n",
    "        self.output = np.zeros(self.y.shape)\n",
    "        self.loss = 0\n",
    "\n",
    "    def forward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        \n",
    "        self.loss = (self.y - self.output ** 2).sum()\n",
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  \n",
    "                            (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), \n",
    "                                    self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "               \n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "        \n",
    "    def describe(self):\n",
    "        print(f'Inputs: {self.input.shape[1]}')\n",
    "        print(f'Weights: {self.weights1.shape[0]} x {self.weights1.shape[1]}')\n",
    "        print(f'Hidden layer: {self.hidden_nodes}')\n",
    "        print(f'Weights: {self.weights2.shape[0]} x {self.weights2.shape[1]}')\n",
    "        print(f'Output layer: {1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, layers, learning_rate):\n",
    "        self.input = x\n",
    "        self.weigths = []\n",
    "        self.activations = []\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        previous_layer = x\n",
    "        for i in range(len(layers)):\n",
    "            current_layer = np.random.rand(previous_layer.shape[1], layers[i])\n",
    "            self.weigths.append(current_layer)\n",
    "            previous_layer = current_layer\n",
    "        \n",
    "        self.weigths.append(np.random.rand(previous_layer.shape[1], 1)) # 1 output\n",
    "                  \n",
    "        self.y = y\n",
    "        self.output = np.zeros(self.y.shape)\n",
    "        self.loss = 0\n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        self.activations = []\n",
    "        self.activations.append(self.input)\n",
    "        \n",
    "        temp = self.input\n",
    "        for i in range(len(self.weigths)):\n",
    "            temp = sigmoid(np.dot(temp, self.weigths[i]))            \n",
    "            self.activations.append(temp)\n",
    "            \n",
    "        self.output = temp        \n",
    "        \n",
    "        self.loss = ((self.y - self.output) ** 2).sum()\n",
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights               \n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        \n",
    "        for i in range(len(self.weigths), 0, -1):\n",
    "                     \n",
    "            chain = 2*(self.y - self.output) * sigmoid_derivative(self.output)\n",
    "            \n",
    "            for layer in range(len(self.weigths), i, -1):\n",
    "                chain = np.dot(chain,\n",
    "                               self.weigths[layer-1].T) \\\n",
    "                * sigmoid_derivative(self.activations[layer-1])\n",
    "                      \n",
    "            d_weight =  np.dot(self.activations[i-1].T, chain)\n",
    "                       \n",
    "            self.weigths[i-1] += self.learning_rate * d_weight\n",
    "        \n",
    "    def describe(self):\n",
    "        print(f'Input: {self.input.shape[1]}')\n",
    "        \n",
    "        for i in range(len(self.weigths)):\n",
    "            print(f'Layer {i}: {self.weigths[i].shape[0]} x {self.weigths[i].shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers = (4,2,5)\n",
    "#myNN = NeuralNetwork(x, y, (10,6))\n",
    "#myNN.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 3\n",
      "Layer 0: 3 x 8\n",
      "Layer 1: 8 x 4\n",
      "Layer 2: 4 x 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array ([   [0, 0, 1],\n",
    "                  [0, 1, 1],\n",
    "                  [1, 0, 1],\n",
    "                  [1, 1, 1]\n",
    "    ])\n",
    "\n",
    "y = np.array ([[0], \n",
    "               [1],\n",
    "               [1],\n",
    "               [0]])\n",
    "\n",
    "myNN = NeuralNetwork(x, y, (8,4), 1e-0)\n",
    "myNN.describe()\n",
    "\n",
    "#myNN.weigths[0] = np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01079741]\n",
      " [0.98747879]\n",
      " [0.98813755]\n",
      " [0.01475056]]\n"
     ]
    }
   ],
   "source": [
    "#myNN.forward()\n",
    "print(myNN.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "myNN.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1117019133768415\n",
      "100 0.9988762003541011\n",
      "200 0.9977292277085708\n",
      "300 0.9948518993419397\n",
      "400 0.9813307246755729\n",
      "500 0.7921703610900679\n",
      "600 0.4758668068898093\n",
      "700 0.028268038830201972\n",
      "800 0.007682019518743047\n",
      "900 0.0043089419713603465\n",
      "1000 0.0029356165851813763\n",
      "1100 0.0022025956402161127\n",
      "1200 0.0017511482703233168\n",
      "1300 0.0014470640228965834\n",
      "1400 0.0012292362828486409\n",
      "1500 0.0010660208714185892\n",
      "1600 0.0009394574944123463\n",
      "1700 0.0008386254780143561\n",
      "1800 0.0007565177505387318\n",
      "1900 0.0006884399119267833\n",
      "[[0.01079741]\n",
      " [0.98747879]\n",
      " [0.98813755]\n",
      " [0.01475056]]\n"
     ]
    }
   ],
   "source": [
    "loss=[]\n",
    "\n",
    "for i in range(2000):\n",
    "    myNN.forward()\n",
    "    if i % 100 == 0:\n",
    "        print(i, myNN.loss)\n",
    "        loss.append(myNN.loss)\n",
    "    myNN.backprop()\n",
    "    \n",
    "print(myNN.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57687046, 0.30359808, 0.08599636, 0.55818046])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x[0], myNN.weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        , -0.        ,  0.        , -0.        ],\n",
       "       [-0.        , -0.        ,  0.        , -0.        ],\n",
       "       [-0.01132414, -0.14968314,  0.02096708, -0.1198421 ]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2*(myNN.y - myNN.output) * sigmoid(myNN.output)\n",
    "#myNN.output, y\n",
    "\n",
    "#y,sigmoid(y)\n",
    "\n",
    "#d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "\n",
    "#myNN.input.shape[1]\n",
    "first_input = np.reshape(myNN.input[0], (1,3))\n",
    "\n",
    "layer1 = sigmoid(np.dot(first_input, myNN.weights1))\n",
    "np.dot(layer1.T, (2*(myNN.y[0] - myNN.output[0]) * sigmoid_derivative(myNN.output[0])))\n",
    "#layer1.T.shape[0], (2*(myNN.y[0] - myNN.output[0]) * sigmoid_derivative(myNN.output[0]))\n",
    "\n",
    "#d_weights1 = np.dot(self.input.T,  \n",
    "#                    (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), \n",
    "#                            self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "np.dot(first_input.T,\n",
    "np.dot(2*(myNN.y[0] - myNN.output[0]) * sigmoid_derivative(myNN.output[0]), \n",
    "                            myNN.weights2.T).reshape(1,4)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57687046, 0.30359808, 0.08599636, 0.55818046])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sigmoid(np.dot(myNN.input, myNN.weights1)).T\n",
    "np.dot(myNN.input[0], myNN.weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82396258]\n",
      " [0.8739199 ]\n",
      " [0.88234037]\n",
      " [0.90557205]\n",
      " [0.78291925]]\n"
     ]
    }
   ],
   "source": [
    "myNN.forward()\n",
    "print(myNN.output)\n",
    "myNN.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1117019133768415,\n",
       " 0.9988762003541011,\n",
       " 0.9977292277085708,\n",
       " 0.9948518993419397,\n",
       " 0.9813307246755729,\n",
       " 0.7921703610900679,\n",
       " 0.4758668068898093,\n",
       " 0.028268038830201972,\n",
       " 0.007682019518743047,\n",
       " 0.0043089419713603465,\n",
       " 0.0029356165851813763,\n",
       " 0.0022025956402161127,\n",
       " 0.0017511482703233168,\n",
       " 0.0014470640228965834,\n",
       " 0.0012292362828486409,\n",
       " 0.0010660208714185892,\n",
       " 0.0009394574944123463,\n",
       " 0.0008386254780143561,\n",
       " 0.0007565177505387318,\n",
       " 0.0006884399119267833]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4hEkMJdRCSCFO4iIhH0/wG5EmaReyR+UAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36 env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
